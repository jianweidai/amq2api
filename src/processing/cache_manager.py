"""
ç¼“å­˜ç®¡ç†æ¨¡å—
å®ç° Anthropic Prompt Caching çš„æ¨¡æ‹ŸåŠŸèƒ½

æ”¹è¿›å†å²:
- é˜¶æ®µ 1: æ·»åŠ åå°æ¸…ç†ä»»åŠ¡ + å¹¶å‘å®‰å…¨ (asyncio.Lock)
- é˜¶æ®µ 2: æ·»åŠ å†…å­˜ç›‘æ§ + ç´§æ€¥æ¸…ç†æœºåˆ¶
- é˜¶æ®µ 3: æ·»åŠ ç¼“å­˜é”®å†²çªæ£€æµ‹ï¼ˆé•¿åº¦æ ¡éªŒï¼‰
"""
import hashlib
import asyncio
import logging
import sys
from dataclasses import dataclass
from datetime import datetime
from typing import Dict, Optional, Tuple, Any, List

logger = logging.getLogger(__name__)


@dataclass
class CacheStatistics:
    """ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
    hit_count: int = 0          # ç¼“å­˜å‘½ä¸­æ¬¡æ•°
    miss_count: int = 0         # ç¼“å­˜æœªå‘½ä¸­æ¬¡æ•°
    eviction_count: int = 0     # æ·˜æ±°æ¬¡æ•°
    
    @property
    def hit_rate(self) -> float:
        """è®¡ç®—ç¼“å­˜å‘½ä¸­ç‡"""
        total = self.hit_count + self.miss_count
        if total == 0:
            return 0.0
        return self.hit_count / total
    
    @property
    def total_requests(self) -> int:
        """æ€»è¯·æ±‚æ•°"""
        return self.hit_count + self.miss_count


@dataclass
class CacheEntry:
    """ç¼“å­˜æ¡ç›®"""
    key: str                    # SHA-256 hash of cacheable content
    token_count: int            # Number of tokens in cached content
    created_at: datetime        # When the cache entry was created
    last_accessed: datetime     # Last access time for LRU
    content_length: int = 0     # é˜¶æ®µ 3: å†…å®¹é•¿åº¦ï¼ˆç”¨äºå†²çªæ£€æµ‹ï¼‰


@dataclass
class CacheResult:
    """ç¼“å­˜æŸ¥è¯¢ç»“æœ"""
    is_hit: bool                          # Whether cache was hit
    cache_creation_input_tokens: int      # Tokens for cache creation (miss)
    cache_read_input_tokens: int          # Tokens read from cache (hit)


class CacheManager:
    """ç¼“å­˜ç®¡ç†å™¨ - æ¨¡æ‹Ÿ Anthropic Prompt Caching è¡Œä¸º"""
    
    # Approximate characters per token (rough estimate for mixed content)
    CHARS_PER_TOKEN = 4
    
    # é…ç½®å¸¸é‡
    MIN_TTL_SECONDS = 60           # æœ€å° TTL: 1 åˆ†é’Ÿ
    MAX_TTL_SECONDS = 604800       # æœ€å¤§ TTL: 7 å¤©
    DEFAULT_TTL_SECONDS = 86400    # é»˜è®¤ TTL: 24 å°æ—¶ (was 300)
    
    MIN_MAX_ENTRIES = 100          # æœ€å°ç¼“å­˜æ¡ç›®æ•°
    MAX_MAX_ENTRIES = 100000       # æœ€å¤§ç¼“å­˜æ¡ç›®æ•°
    DEFAULT_MAX_ENTRIES = 5000     # é»˜è®¤ç¼“å­˜æ¡ç›®æ•° (was 1000)
    
    BATCH_EVICTION_PERCENT = 10    # æ‰¹é‡æ·˜æ±°ç™¾åˆ†æ¯”
    CLEANUP_INTERVAL_SECONDS = 300  # åå°æ¸…ç†é—´éš”: 5 åˆ†é’Ÿ
    
    # é˜¶æ®µ 2: å†…å­˜ç›‘æ§é…ç½®
    MEMORY_WARNING_THRESHOLD_MB = 100   # å†…å­˜è­¦å‘Šé˜ˆå€¼: 100MB
    MEMORY_CRITICAL_THRESHOLD_MB = 200  # å†…å­˜ä¸´ç•Œé˜ˆå€¼: 200MB
    EMERGENCY_EVICTION_PERCENT = 50     # ç´§æ€¥æ¸…ç†ç™¾åˆ†æ¯”: 50%
    
    def __init__(
        self, 
        ttl_seconds: int = DEFAULT_TTL_SECONDS, 
        max_entries: int = DEFAULT_MAX_ENTRIES,
        auto_cache_system: bool = True,
        auto_cache_history: bool = True,
        auto_cache_tools: bool = True,
        min_cacheable_tokens: int = 1024
    ):
        """
        åˆå§‹åŒ–ç¼“å­˜ç®¡ç†å™¨
        
        Args:
            ttl_seconds: ç¼“å­˜æ¡ç›®çš„ç”Ÿå­˜æ—¶é—´ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤ 86400 ç§’ï¼ˆ24 å°æ—¶ï¼‰
            max_entries: æœ€å¤§ç¼“å­˜æ¡ç›®æ•°ï¼Œé»˜è®¤ 5000
            auto_cache_system: è‡ªåŠ¨ç¼“å­˜ system promptï¼ˆé»˜è®¤ Trueï¼‰
            auto_cache_history: è‡ªåŠ¨ç¼“å­˜å†å²æ¶ˆæ¯ï¼ˆé»˜è®¤ Trueï¼‰
            auto_cache_tools: è‡ªåŠ¨ç¼“å­˜ tools å®šä¹‰ï¼ˆé»˜è®¤ Trueï¼‰
            min_cacheable_tokens: æœ€å°å¯ç¼“å­˜ token æ•°ï¼ˆé»˜è®¤ 1024ï¼Œç¬¦åˆ Anthropic è¦æ±‚ï¼‰
            
        Raises:
            ValueError: å¦‚æœå‚æ•°è¶…å‡ºæœ‰æ•ˆèŒƒå›´
        """
        # éªŒè¯å¹¶è®¾ç½® TTL
        if not self.MIN_TTL_SECONDS <= ttl_seconds <= self.MAX_TTL_SECONDS:
            raise ValueError(
                f"ttl_seconds must be between {self.MIN_TTL_SECONDS} and {self.MAX_TTL_SECONDS}"
            )
        
        # éªŒè¯å¹¶è®¾ç½® max_entries
        if not self.MIN_MAX_ENTRIES <= max_entries <= self.MAX_MAX_ENTRIES:
            raise ValueError(
                f"max_entries must be between {self.MIN_MAX_ENTRIES} and {self.MAX_MAX_ENTRIES}"
            )
        
        self._cache: Dict[str, CacheEntry] = {}
        self._ttl = ttl_seconds
        self._max_entries = max_entries
        self._stats = CacheStatistics()
        
        # è‡ªåŠ¨ç¼“å­˜é…ç½®
        self._auto_cache_system = auto_cache_system
        self._auto_cache_history = auto_cache_history
        self._auto_cache_tools = auto_cache_tools
        self._min_cacheable_tokens = min_cacheable_tokens
        
        # é˜¶æ®µ 1: å¹¶å‘å®‰å…¨ - æ·»åŠ å¼‚æ­¥é”
        self._lock = asyncio.Lock()
        
        # é˜¶æ®µ 1: åå°æ¸…ç†ä»»åŠ¡
        self._cleanup_task: Optional[asyncio.Task] = None
        self._cleanup_interval = self.CLEANUP_INTERVAL_SECONDS
    
    def calculate_cache_key(self, content: str) -> str:
        """
        è®¡ç®—ç¼“å­˜é”®ï¼ˆSHA-256 + é•¿åº¦ï¼‰
        
        é˜¶æ®µ 3: å°†å†…å®¹é•¿åº¦ç¼–ç åˆ°é”®ä¸­ï¼Œç”¨äºå†²çªæ£€æµ‹
        
        Args:
            content: å¯ç¼“å­˜çš„å†…å®¹å­—ç¬¦ä¸²
            
        Returns:
            æ ¼å¼ä¸º "hash:length" çš„ç¼“å­˜é”®
        """
        hash_value = hashlib.sha256(content.encode('utf-8')).hexdigest()
        # å°†é•¿åº¦ç¼–ç åˆ°é”®ä¸­ï¼Œæ ¼å¼: hash:length
        return f"{hash_value}:{len(content)}"
    
    async def start_background_cleanup(self):
        """
        é˜¶æ®µ 1: å¯åŠ¨åå°æ¸…ç†ä»»åŠ¡
        
        å®šæœŸæ¸…ç†è¿‡æœŸç¼“å­˜æ¡ç›®ï¼Œé¿å…åœ¨è¯·æ±‚å¤„ç†æ—¶é˜»å¡
        """
        async def cleanup_loop():
            while True:
                try:
                    await asyncio.sleep(self._cleanup_interval)
                    await self._evict_expired_async()
                    logger.info(
                        f"ğŸ§¹ åå°æ¸…ç†å®Œæˆ - å½“å‰ç¼“å­˜: {len(self._cache)}/{self._max_entries} æ¡ç›®, "
                        f"å‘½ä¸­ç‡: {self._stats.hit_rate * 100:.2f}%"
                    )
                except asyncio.CancelledError:
                    logger.info("åå°æ¸…ç†ä»»åŠ¡å·²å–æ¶ˆ")
                    raise
                except Exception as e:
                    logger.error(f"åå°æ¸…ç†ä»»åŠ¡å¼‚å¸¸: {e}", exc_info=True)
        
        self._cleanup_task = asyncio.create_task(cleanup_loop())
        logger.info(f"âœ… ç¼“å­˜åå°æ¸…ç†ä»»åŠ¡å·²å¯åŠ¨ (é—´éš”: {self._cleanup_interval}s)")
    
    async def stop_background_cleanup(self):
        """
        é˜¶æ®µ 1: åœæ­¢åå°æ¸…ç†ä»»åŠ¡
        """
        if self._cleanup_task:
            self._cleanup_task.cancel()
            try:
                await self._cleanup_task
            except asyncio.CancelledError:
                pass
            logger.info("âœ… ç¼“å­˜åå°æ¸…ç†ä»»åŠ¡å·²åœæ­¢")
    
    async def check_cache_async(self, key: str, token_count: int, content_length: int = 0) -> CacheResult:
        """
        é˜¶æ®µ 1: å¼‚æ­¥ç‰ˆæœ¬çš„ç¼“å­˜æ£€æŸ¥ï¼ˆå¸¦å¹¶å‘å®‰å…¨ï¼‰
        é˜¶æ®µ 3: æ·»åŠ å†…å®¹é•¿åº¦å‚æ•°ç”¨äºå†²çªæ£€æµ‹
        
        Args:
            key: ç¼“å­˜é”®ï¼ˆæ ¼å¼: hash:lengthï¼‰
            token_count: ç¼“å­˜å†…å®¹çš„ token æ•°é‡
            content_length: å†…å®¹é•¿åº¦ï¼ˆç”¨äºå†²çªæ£€æµ‹ï¼‰
            
        Returns:
            CacheResult åŒ…å«å‘½ä¸­çŠ¶æ€å’Œ token ç»Ÿè®¡
        """
        async with self._lock:
            now = datetime.now()
            
            if key in self._cache:
                entry = self._cache[key]
                
                # é˜¶æ®µ 3: äºŒæ¬¡æ ¡éªŒ - æ£€æŸ¥å†…å®¹é•¿åº¦æ˜¯å¦åŒ¹é…
                if content_length > 0:
                    # ä»é”®ä¸­æå–é¢„æœŸé•¿åº¦
                    try:
                        expected_length = int(key.split(':')[1])
                        if entry.content_length != expected_length:
                            # æ£€æµ‹åˆ°å“ˆå¸Œå†²çªï¼
                            logger.warning(
                                f"ğŸš¨ æ£€æµ‹åˆ°ç¼“å­˜é”®å†²çª: {key[:16]}... "
                                f"(å­˜å‚¨é•¿åº¦: {entry.content_length}, é¢„æœŸé•¿åº¦: {expected_length})"
                            )
                            # åˆ é™¤æ—§æ¡ç›®ï¼Œè§†ä¸ºæœªå‘½ä¸­
                            del self._cache[key]
                            self._stats.miss_count += 1
                            # ç»§ç»­åˆ›å»ºæ–°æ¡ç›®ï¼ˆä¸‹é¢çš„ else åˆ†æ”¯ï¼‰
                        else:
                            # é•¿åº¦åŒ¹é…ï¼ŒçœŸæ­£çš„ç¼“å­˜å‘½ä¸­
                            entry.last_accessed = now
                            self._stats.hit_count += 1
                            return CacheResult(
                                is_hit=True,
                                cache_creation_input_tokens=0,
                                cache_read_input_tokens=entry.token_count
                            )
                    except (IndexError, ValueError):
                        # é”®æ ¼å¼ä¸æ­£ç¡®ï¼Œè§†ä¸ºæœªå‘½ä¸­
                        logger.warning(f"âš ï¸ ç¼“å­˜é”®æ ¼å¼é”™è¯¯: {key}")
                        del self._cache[key]
                        self._stats.miss_count += 1
                else:
                    # æ²¡æœ‰æä¾› content_lengthï¼Œè·³è¿‡å†²çªæ£€æµ‹ï¼ˆå‘åå…¼å®¹ï¼‰
                    entry.last_accessed = now
                    self._stats.hit_count += 1
                    return CacheResult(
                        is_hit=True,
                        cache_creation_input_tokens=0,
                        cache_read_input_tokens=entry.token_count
                    )
            
            # ç¼“å­˜æœªå‘½ä¸­æˆ–å†²çª - åˆ›å»ºæ–°æ¡ç›®
            if key not in self._cache:  # ç¡®ä¿ä¸æ˜¯ä»å†²çªæ£€æµ‹è·³è½¬è¿‡æ¥çš„
                self._stats.miss_count += 1
            
            # é˜¶æ®µ 2: åœ¨æ·»åŠ æ–°æ¡ç›®å‰æ£€æŸ¥å†…å­˜ä½¿ç”¨
            if len(self._cache) >= self._max_entries:
                memory_info = self.estimate_memory_usage()
                
                if memory_info['critical']:
                    logger.error(f"ğŸš¨ å†…å­˜ä½¿ç”¨è¾¾åˆ°ä¸´ç•Œå€¼: {memory_info['mb']}MBï¼Œæ‰§è¡Œç´§æ€¥æ¸…ç†")
                    self.emergency_cleanup()
                elif memory_info['warning']:
                    logger.warning(f"âš ï¸ å†…å­˜ä½¿ç”¨æ¥è¿‘é˜ˆå€¼: {memory_info['mb']}MBï¼Œæ‰§è¡Œæ‰¹é‡æ·˜æ±°")
                    self._evict_lru_batch()
                else:
                    self._evict_lru_batch()
            
            self._cache[key] = CacheEntry(
                key=key,
                token_count=token_count,
                created_at=now,
                last_accessed=now,
                content_length=content_length  # é˜¶æ®µ 3: å­˜å‚¨å†…å®¹é•¿åº¦
            )
            return CacheResult(
                is_hit=False,
                cache_creation_input_tokens=token_count,
                cache_read_input_tokens=0
            )
    
    def check_cache(self, key: str, token_count: int, content_length: int = 0) -> CacheResult:
        """
        åŒæ­¥ç‰ˆæœ¬çš„ç¼“å­˜æ£€æŸ¥ï¼ˆä¿ç•™å‘åå…¼å®¹ï¼‰
        é˜¶æ®µ 3: æ·»åŠ å†…å®¹é•¿åº¦å‚æ•°ç”¨äºå†²çªæ£€æµ‹
        
        æ³¨æ„: æ¨èä½¿ç”¨ check_cache_async() ä»¥è·å¾—æ›´å¥½çš„å¹¶å‘æ€§èƒ½
        
        Args:
            key: ç¼“å­˜é”®ï¼ˆæ ¼å¼: hash:lengthï¼‰
            token_count: ç¼“å­˜å†…å®¹çš„ token æ•°é‡
            content_length: å†…å®¹é•¿åº¦ï¼ˆç”¨äºå†²çªæ£€æµ‹ï¼‰
            
        Returns:
            CacheResult åŒ…å«å‘½ä¸­çŠ¶æ€å’Œ token ç»Ÿè®¡
        """
        # é˜¶æ®µ 1: ç§»é™¤åŒæ­¥æ¸…ç†ï¼Œç”±åå°ä»»åŠ¡å¤„ç†
        # self._evict_expired()  # å·²ç§»é™¤
        
        now = datetime.now()
        
        if key in self._cache:
            entry = self._cache[key]
            
            # é˜¶æ®µ 3: äºŒæ¬¡æ ¡éªŒ - æ£€æŸ¥å†…å®¹é•¿åº¦æ˜¯å¦åŒ¹é…
            if content_length > 0:
                try:
                    expected_length = int(key.split(':')[1])
                    if entry.content_length != expected_length:
                        # æ£€æµ‹åˆ°å“ˆå¸Œå†²çªï¼
                        logger.warning(
                            f"ğŸš¨ æ£€æµ‹åˆ°ç¼“å­˜é”®å†²çª: {key[:16]}... "
                            f"(å­˜å‚¨é•¿åº¦: {entry.content_length}, é¢„æœŸé•¿åº¦: {expected_length})"
                        )
                        del self._cache[key]
                        self._stats.miss_count += 1
                        # ç»§ç»­åˆ›å»ºæ–°æ¡ç›®
                    else:
                        # é•¿åº¦åŒ¹é…ï¼ŒçœŸæ­£çš„ç¼“å­˜å‘½ä¸­
                        entry.last_accessed = now
                        self._stats.hit_count += 1
                        return CacheResult(
                            is_hit=True,
                            cache_creation_input_tokens=0,
                            cache_read_input_tokens=entry.token_count
                        )
                except (IndexError, ValueError):
                    logger.warning(f"âš ï¸ ç¼“å­˜é”®æ ¼å¼é”™è¯¯: {key}")
                    del self._cache[key]
                    self._stats.miss_count += 1
            else:
                # æ²¡æœ‰æä¾› content_lengthï¼Œè·³è¿‡å†²çªæ£€æµ‹
                entry.last_accessed = now
                self._stats.hit_count += 1
                return CacheResult(
                    is_hit=True,
                    cache_creation_input_tokens=0,
                    cache_read_input_tokens=entry.token_count
                )
        
        # ç¼“å­˜æœªå‘½ä¸­æˆ–å†²çª - åˆ›å»ºæ–°æ¡ç›®
        if key not in self._cache:
            self._stats.miss_count += 1
        
        # å…ˆæ£€æŸ¥æ˜¯å¦éœ€è¦æ‰¹é‡ LRU æ·˜æ±°
        if len(self._cache) >= self._max_entries:
            self._evict_lru_batch()
        
        self._cache[key] = CacheEntry(
            key=key,
            token_count=token_count,
            created_at=now,
            last_accessed=now,
            content_length=content_length  # é˜¶æ®µ 3: å­˜å‚¨å†…å®¹é•¿åº¦
        )
        return CacheResult(
            is_hit=False,
            cache_creation_input_tokens=token_count,
            cache_read_input_tokens=0
        )
    
    async def _evict_expired_async(self) -> None:
        """
        é˜¶æ®µ 1: å¼‚æ­¥ç‰ˆæœ¬çš„è¿‡æœŸæ¸…ç†ï¼ˆå¸¦å¹¶å‘å®‰å…¨ï¼‰
        
        ä½¿ç”¨ last_accessed + TTL åˆ¤æ–­è¿‡æœŸï¼Œè€Œé created_at + TTL
        """
        async with self._lock:
            now = datetime.now()
            expired_keys = [
                key for key, entry in self._cache.items()
                if (now - entry.last_accessed).total_seconds() > self._ttl
            ]
            for key in expired_keys:
                del self._cache[key]
                self._stats.eviction_count += 1
            
            if expired_keys:
                logger.debug(f"æ¸…ç†äº† {len(expired_keys)} ä¸ªè¿‡æœŸç¼“å­˜æ¡ç›®")
    
    def _evict_expired(self) -> None:
        """
        æ¸…ç†è¿‡æœŸæ¡ç›®ï¼ˆåŸºäºæ»‘åŠ¨çª—å£ TTLï¼‰
        
        æ³¨æ„: æ­¤æ–¹æ³•å·²è¢«åå°æ¸…ç†ä»»åŠ¡æ›¿ä»£ï¼Œä¿ç•™ä»…ç”¨äºå‘åå…¼å®¹
        ä½¿ç”¨ last_accessed + TTL åˆ¤æ–­è¿‡æœŸï¼Œè€Œé created_at + TTL
        """
        now = datetime.now()
        expired_keys = [
            key for key, entry in self._cache.items()
            if (now - entry.last_accessed).total_seconds() > self._ttl
        ]
        for key in expired_keys:
            del self._cache[key]
            self._stats.eviction_count += 1
    
    def _evict_lru_batch(self) -> None:
        """
        æ‰¹é‡ LRU æ·˜æ±°
        
        æ·˜æ±° BATCH_EVICTION_PERCENT% çš„æ¡ç›®ï¼Œä¼˜å…ˆæ·˜æ±°ï¼š
        1. æœ€ä¹…æœªè®¿é—®çš„æ¡ç›®
        2. åœ¨è®¿é—®æ—¶é—´ç›¸è¿‘æ—¶ï¼Œä¼˜å…ˆæ·˜æ±° token æ•°è¾ƒå°‘çš„æ¡ç›®
        """
        if not self._cache:
            return
        
        # è®¡ç®—éœ€è¦æ·˜æ±°çš„æ•°é‡
        evict_count = max(1, len(self._cache) * self.BATCH_EVICTION_PERCENT // 100)
        
        # æŒ‰ (last_accessed, token_count) æ’åºï¼Œæœ€æ—§ä¸”æœ€å°çš„ä¼˜å…ˆæ·˜æ±°
        sorted_entries = sorted(
            self._cache.items(),
            key=lambda x: (x[1].last_accessed, x[1].token_count)
        )
        
        # æ·˜æ±°å‰ evict_count ä¸ªæ¡ç›®
        for key, _ in sorted_entries[:evict_count]:
            del self._cache[key]
            self._stats.eviction_count += 1
    
    def estimate_memory_usage(self) -> Dict[str, Any]:
        """
        é˜¶æ®µ 2: ä¼°ç®—ç¼“å­˜å†…å­˜ä½¿ç”¨
        
        Returns:
            åŒ…å«å†…å­˜ä½¿ç”¨ä¿¡æ¯çš„å­—å…¸:
            - bytes: æ€»å­—èŠ‚æ•°
            - mb: MB æ•°ï¼ˆä¿ç•™2ä½å°æ•°ï¼‰
            - entries: ç¼“å­˜æ¡ç›®æ•°
            - warning: æ˜¯å¦è¾¾åˆ°è­¦å‘Šé˜ˆå€¼
            - critical: æ˜¯å¦è¾¾åˆ°ä¸´ç•Œé˜ˆå€¼
        """
        total_bytes = 0
        
        for key, entry in self._cache.items():
            # ä¼°ç®—æ¯ä¸ªæ¡ç›®çš„å†…å­˜å ç”¨
            # key (64 å­—èŠ‚ SHA-256 hex string)
            total_bytes += sys.getsizeof(key)
            # CacheEntry å¯¹è±¡æœ¬èº«
            total_bytes += sys.getsizeof(entry)
            # token_count ç²—ç•¥ä¼°ç®—ï¼ˆå‡è®¾æ¯ä¸ª token 4 å­—èŠ‚ï¼‰
            total_bytes += entry.token_count * 4
        
        mb = total_bytes / (1024 * 1024)
        
        return {
            'bytes': total_bytes,
            'mb': round(mb, 2),
            'entries': len(self._cache),
            'max_entries': self._max_entries,
            'warning': mb > self.MEMORY_WARNING_THRESHOLD_MB,
            'critical': mb > self.MEMORY_CRITICAL_THRESHOLD_MB
        }
    
    def emergency_cleanup(self) -> int:
        """
        é˜¶æ®µ 2: ç´§æ€¥æ¸…ç† - æ¸…é™¤ 50% çš„ç¼“å­˜
        
        åœ¨å†…å­˜ä½¿ç”¨è¾¾åˆ°ä¸´ç•Œå€¼æ—¶è°ƒç”¨ï¼Œå¼ºåˆ¶æ¸…ç†ä¸€åŠçš„ç¼“å­˜æ¡ç›®
        
        Returns:
            æ¸…ç†çš„æ¡ç›®æ•°
        """
        if not self._cache:
            return 0
        
        evict_count = len(self._cache) * self.EMERGENCY_EVICTION_PERCENT // 100
        evict_count = max(1, evict_count)  # è‡³å°‘æ¸…ç† 1 ä¸ª
        
        # æŒ‰è®¿é—®æ—¶é—´æ’åºï¼Œåˆ é™¤æœ€æ—§çš„ 50%
        sorted_entries = sorted(
            self._cache.items(),
            key=lambda x: x[1].last_accessed
        )
        
        cleaned = 0
        for key, _ in sorted_entries[:evict_count]:
            del self._cache[key]
            self._stats.eviction_count += 1
            cleaned += 1
        
        logger.warning(f"ğŸš¨ ç´§æ€¥æ¸…ç†å®Œæˆï¼šåˆ é™¤ {cleaned} æ¡ç¼“å­˜ï¼ˆ{self.EMERGENCY_EVICTION_PERCENT}%ï¼‰")
        return cleaned
    
    def get_statistics(self) -> CacheStatistics:
        """è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
        return self._stats
    
    def export_statistics(self) -> Dict[str, Any]:
        """
        å¯¼å‡ºè¯¦ç»†ç»Ÿè®¡ä¿¡æ¯ï¼ˆç”¨äº dashboard æ˜¾ç¤ºï¼‰
        
        Returns:
            åŒ…å«ç»Ÿè®¡ã€é…ç½®ã€å†…å­˜ä½¿ç”¨ç­‰å®Œæ•´ä¿¡æ¯çš„å­—å…¸
        """
        memory_info = self.estimate_memory_usage()
        
        return {
            "enabled": True,
            "stats": {
                "hit_count": self._stats.hit_count,
                "miss_count": self._stats.miss_count,
                "hit_rate": round(self._stats.hit_rate * 100, 2),
                "hit_rate_raw": self._stats.hit_rate,
                "eviction_count": self._stats.eviction_count,
                "total_requests": self._stats.total_requests,
            },
            "config": {
                "ttl_seconds": self._ttl,
                "max_entries": self._max_entries,
                "auto_cache_system": self._auto_cache_system,
                "auto_cache_history": self._auto_cache_history,
                "auto_cache_tools": self._auto_cache_tools,
                "min_cacheable_tokens": self._min_cacheable_tokens,
            },
            "memory": {
                "bytes": memory_info['bytes'],
                "mb": memory_info['mb'],
                "warning": memory_info['warning'],
                "critical": memory_info['critical'],
                "warning_threshold_mb": self.MEMORY_WARNING_THRESHOLD_MB,
                "critical_threshold_mb": self.MEMORY_CRITICAL_THRESHOLD_MB,
            },
            "cache": {
                "size": self.size,
                "max_entries": self._max_entries,
                "usage_percent": round((self.size / self._max_entries) * 100, 2) if self._max_entries > 0 else 0,
            }
        }
    
    def clear(self) -> None:
        """æ¸…ç©ºç¼“å­˜å¹¶é‡ç½®ç»Ÿè®¡"""
        self._cache.clear()
        self._stats = CacheStatistics()
    
    def prewarm(self, contents: List[str]) -> int:
        """
        é¢„çƒ­ç¼“å­˜
        
        éå†å†…å®¹åˆ—è¡¨ï¼Œä¸ºæ¯ä¸ªåˆ›å»ºç¼“å­˜æ¡ç›®ã€‚ä½¿ç”¨ _estimate_token_count ä¼°ç®— token æ•°ã€‚
        å°Šé‡ max_entries å®¹é‡é™åˆ¶ã€‚
        
        Args:
            contents: è¦é¢„çƒ­çš„å†…å®¹åˆ—è¡¨
            
        Returns:
            å®é™…æ·»åŠ çš„æ¡ç›®æ•°
        """
        added = 0
        now = datetime.now()
        
        for content in contents:
            # æ£€æŸ¥æ˜¯å¦å·²è¾¾åˆ°å®¹é‡ä¸Šé™
            if len(self._cache) >= self._max_entries:
                break
            
            key = self.calculate_cache_key(content)
            # åªæ·»åŠ ä¸å­˜åœ¨çš„æ¡ç›®
            if key not in self._cache:
                token_count = self._estimate_token_count(content)
                self._cache[key] = CacheEntry(
                    key=key,
                    token_count=token_count,
                    created_at=now,
                    last_accessed=now,
                    content_length=len(content)  # é˜¶æ®µ 3: å­˜å‚¨å†…å®¹é•¿åº¦
                )
                added += 1
        
        return added
    
    def _estimate_token_count(self, text: str) -> int:
        """
        ä¼°ç®—æ–‡æœ¬çš„ token æ•°é‡
        
        ä½¿ç”¨ç®€å•çš„å­—ç¬¦æ•°é™¤ä»¥å¹³å‡å­—ç¬¦/token æ¯”ç‡æ¥ä¼°ç®—ã€‚
        è¿™æ˜¯ä¸€ä¸ªç²—ç•¥ä¼°è®¡ï¼Œå®é™… token æ•°é‡å–å†³äºå…·ä½“çš„ tokenizerã€‚
        
        Args:
            text: è¦ä¼°ç®—çš„æ–‡æœ¬
            
        Returns:
            ä¼°ç®—çš„ token æ•°é‡
        """
        if not text:
            return 0
        return max(1, len(text) // self.CHARS_PER_TOKEN)
    
    @property
    def size(self) -> int:
        """å½“å‰ç¼“å­˜æ¡ç›®æ•°"""
        return len(self._cache)
    
    @property
    def ttl(self) -> int:
        """å½“å‰ TTL è®¾ç½®ï¼ˆç§’ï¼‰"""
        return self._ttl
    
    @property
    def max_entries(self) -> int:
        """å½“å‰æœ€å¤§æ¡ç›®æ•°è®¾ç½®"""
        return self._max_entries
    
    def extract_cacheable_content(self, request_data: Dict[str, Any]) -> Tuple[str, int]:
        """
        ä»è¯·æ±‚ä¸­æå–å¯ç¼“å­˜å†…å®¹å’Œ token æ•°
        
        æ”¹è¿›ç­–ç•¥ï¼š
        1. ä¼˜å…ˆæå–å¸¦ cache_control æ ‡è®°çš„å†…å®¹ï¼ˆå…¼å®¹ Anthropic æ ‡å‡†ï¼‰
        2. è‡ªåŠ¨ç¼“å­˜ system promptï¼ˆå¦‚æœå¯ç”¨ï¼‰
        3. è‡ªåŠ¨ç¼“å­˜å†å²æ¶ˆæ¯ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        4. è‡ªåŠ¨ç¼“å­˜ tools å®šä¹‰ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        
        Args:
            request_data: Claude API è¯·æ±‚æ•°æ®å­—å…¸
            
        Returns:
            Tuple[str, int]: (å¯ç¼“å­˜å†…å®¹å­—ç¬¦ä¸², token æ•°é‡)
            å¦‚æœæ²¡æœ‰å¯ç¼“å­˜å†…å®¹ï¼Œè¿”å› ("", 0)
        """
        cacheable_parts: List[str] = []
        
        # 1. ä¼˜å…ˆæå–å¸¦ cache_control æ ‡è®°çš„å†…å®¹ï¼ˆä¿æŒå‘åå…¼å®¹ï¼‰
        system = request_data.get("system")
        if system:
            system_cacheable = self._extract_cacheable_from_system(system)
            if system_cacheable:
                cacheable_parts.append(system_cacheable)
        
        messages = request_data.get("messages", [])
        for message in messages:
            message_cacheable = self._extract_cacheable_from_message(message)
            if message_cacheable:
                cacheable_parts.append(message_cacheable)
        
        # 2. å¦‚æœæ²¡æœ‰æ‰¾åˆ°å¸¦ cache_control çš„å†…å®¹ï¼Œä½¿ç”¨è‡ªåŠ¨ç¼“å­˜ç­–ç•¥
        if not cacheable_parts:
            # 2.1 è‡ªåŠ¨ç¼“å­˜ system prompt
            if self._auto_cache_system and system:
                system_text = self._extract_system_text(system)
                if system_text:
                    cacheable_parts.append(f"[SYSTEM]\n{system_text}")
            
            # 2.2 è‡ªåŠ¨ç¼“å­˜å†å²æ¶ˆæ¯ï¼ˆé™¤äº†æœ€åä¸€æ¡ï¼‰
            if self._auto_cache_history and len(messages) > 1:
                history_text = self._extract_history_text(messages[:-1])
                if history_text:
                    cacheable_parts.append(f"[HISTORY]\n{history_text}")
            
            # 2.3 è‡ªåŠ¨ç¼“å­˜ tools å®šä¹‰
            if self._auto_cache_tools:
                tools = request_data.get("tools")
                if tools:
                    import json
                    tools_text = json.dumps(tools, sort_keys=True, ensure_ascii=False)
                    cacheable_parts.append(f"[TOOLS]\n{tools_text}")
        
        # 3. åˆå¹¶æ‰€æœ‰å¯ç¼“å­˜å†…å®¹
        if not cacheable_parts:
            return ("", 0)
        
        combined_content = "\n---\n".join(cacheable_parts)
        token_count = self._estimate_token_count(combined_content)
        
        # 4. æ£€æŸ¥æ˜¯å¦æ»¡è¶³æœ€å° token è¦æ±‚
        if token_count < self._min_cacheable_tokens:
            logger.debug(f"å¯ç¼“å­˜å†…å®¹å¤ªå°‘ï¼ˆ{token_count} tokens < {self._min_cacheable_tokens}ï¼‰ï¼Œè·³è¿‡ç¼“å­˜")
            return ("", 0)
        
        return (combined_content, token_count)
    
    def _extract_cacheable_from_system(self, system: Any) -> str:
        """
        ä» system prompt ä¸­æå–å¯ç¼“å­˜å†…å®¹
        
        system å¯ä»¥æ˜¯:
        - å­—ç¬¦ä¸²: ä¸æ”¯æŒ cache_control
        - æ•°ç»„: æ¯ä¸ªå…ƒç´ å¯èƒ½åŒ…å« cache_control
        
        Args:
            system: system prompt (å­—ç¬¦ä¸²æˆ–æ•°ç»„)
            
        Returns:
            å¯ç¼“å­˜å†…å®¹å­—ç¬¦ä¸²ï¼Œå¦‚æœæ²¡æœ‰åˆ™è¿”å›ç©ºå­—ç¬¦ä¸²
        """
        if isinstance(system, str):
            # å­—ç¬¦ä¸²æ ¼å¼ä¸æ”¯æŒ cache_control
            return ""
        
        if not isinstance(system, list):
            return ""
        
        cacheable_texts: List[str] = []
        
        for block in system:
            if not isinstance(block, dict):
                continue
            
            # æ£€æŸ¥æ˜¯å¦æœ‰ cache_control
            cache_control = block.get("cache_control")
            if not cache_control:
                continue
            
            # éªŒè¯ cache_control ç±»å‹æ˜¯å¦ä¸º "ephemeral"
            cache_type = cache_control.get("type") if isinstance(cache_control, dict) else None
            if cache_type != "ephemeral":
                continue
            
            # æå–æ–‡æœ¬å†…å®¹
            if block.get("type") == "text":
                text = block.get("text", "")
                if text:
                    cacheable_texts.append(text)
        
        return "\n".join(cacheable_texts)
    
    def _extract_cacheable_from_message(self, message: Dict[str, Any]) -> str:
        """
        ä»æ¶ˆæ¯ä¸­æå–å¯ç¼“å­˜å†…å®¹
        
        æ¶ˆæ¯çš„ content å¯ä»¥æ˜¯:
        - å­—ç¬¦ä¸²: ä¸æ”¯æŒ cache_control
        - æ•°ç»„: æ¯ä¸ªå†…å®¹å—å¯èƒ½åŒ…å« cache_control
        
        Args:
            message: æ¶ˆæ¯å­—å…¸
            
        Returns:
            å¯ç¼“å­˜å†…å®¹å­—ç¬¦ä¸²ï¼Œå¦‚æœæ²¡æœ‰åˆ™è¿”å›ç©ºå­—ç¬¦ä¸²
        """
        content = message.get("content")
        
        if isinstance(content, str):
            # å­—ç¬¦ä¸²æ ¼å¼ä¸æ”¯æŒ cache_control
            return ""
        
        if not isinstance(content, list):
            return ""
        
        cacheable_texts: List[str] = []
        
        for block in content:
            if not isinstance(block, dict):
                continue
            
            # æ£€æŸ¥æ˜¯å¦æœ‰ cache_control
            cache_control = block.get("cache_control")
            if not cache_control:
                continue
            
            # éªŒè¯ cache_control ç±»å‹æ˜¯å¦ä¸º "ephemeral"
            cache_type = cache_control.get("type") if isinstance(cache_control, dict) else None
            if cache_type != "ephemeral":
                continue
            
            # æ ¹æ®å†…å®¹å—ç±»å‹æå–å†…å®¹
            block_type = block.get("type")
            
            if block_type == "text":
                text = block.get("text", "")
                if text:
                    cacheable_texts.append(text)
            elif block_type == "image":
                # å¯¹äºå›¾ç‰‡ï¼Œä½¿ç”¨ source çš„å­—ç¬¦ä¸²è¡¨ç¤º
                source = block.get("source", {})
                if source:
                    import json
                    cacheable_texts.append(json.dumps(source, sort_keys=True))
            elif block_type == "tool_use":
                # å¯¹äº tool_useï¼Œä½¿ç”¨ name å’Œ input çš„ç»„åˆ
                name = block.get("name", "")
                input_data = block.get("input", {})
                if name:
                    import json
                    cacheable_texts.append(f"{name}:{json.dumps(input_data, sort_keys=True)}")
            elif block_type == "tool_result":
                # å¯¹äº tool_resultï¼Œä½¿ç”¨ tool_use_id å’Œ content
                tool_use_id = block.get("tool_use_id", "")
                result_content = block.get("content", "")
                if tool_use_id:
                    if isinstance(result_content, str):
                        cacheable_texts.append(f"{tool_use_id}:{result_content}")
                    else:
                        import json
                        cacheable_texts.append(f"{tool_use_id}:{json.dumps(result_content, sort_keys=True)}")
        
        return "\n".join(cacheable_texts)
    
    def _extract_system_text(self, system: Any) -> str:
        """
        æå– system prompt çš„æ–‡æœ¬å†…å®¹ï¼ˆä¸ä¾èµ– cache_controlï¼‰
        
        Args:
            system: system prompt (å­—ç¬¦ä¸²æˆ–æ•°ç»„)
            
        Returns:
            system prompt æ–‡æœ¬
        """
        if isinstance(system, str):
            return system
        
        if not isinstance(system, list):
            return ""
        
        texts: List[str] = []
        for block in system:
            if isinstance(block, dict) and block.get("type") == "text":
                text = block.get("text", "")
                if text:
                    texts.append(text)
        
        return "\n".join(texts)
    
    def _extract_history_text(self, messages: List[Dict[str, Any]]) -> str:
        """
        æå–å†å²æ¶ˆæ¯çš„æ–‡æœ¬å†…å®¹ï¼ˆä¸ä¾èµ– cache_controlï¼‰
        
        Args:
            messages: æ¶ˆæ¯åˆ—è¡¨
            
        Returns:
            å†å²æ¶ˆæ¯æ–‡æœ¬
        """
        texts: List[str] = []
        
        for message in messages:
            role = message.get("role", "user")
            content = message.get("content", "")
            
            if isinstance(content, str):
                texts.append(f"{role}: {content}")
            elif isinstance(content, list):
                message_parts = []
                for block in content:
                    if isinstance(block, dict):
                        block_type = block.get("type")
                        if block_type == "text":
                            message_parts.append(block.get("text", ""))
                        elif block_type == "tool_use":
                            import json
                            name = block.get("name", "")
                            input_data = block.get("input", {})
                            message_parts.append(f"[tool_use:{name}] {json.dumps(input_data)}")
                        elif block_type == "tool_result":
                            tool_use_id = block.get("tool_use_id", "")
                            result_content = block.get("content", "")
                            if isinstance(result_content, str):
                                message_parts.append(f"[tool_result:{tool_use_id}] {result_content}")
                            else:
                                import json
                                message_parts.append(f"[tool_result:{tool_use_id}] {json.dumps(result_content)}")
                
                if message_parts:
                    texts.append(f"{role}: {' '.join(message_parts)}")
        
        return "\n".join(texts)

